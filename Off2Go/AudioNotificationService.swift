//
//  AudioNotificationService.swift
//  Off2Go
//
//  Created by Heidie Lee on 2025/5/27.
//

import Foundation
import AVFoundation
import MediaPlayer
import Combine

class AudioNotificationService: NSObject, ObservableObject {
    static let shared = AudioNotificationService()
    
    // éŸ³é »è¨­å®š
    @Published var isAudioEnabled: Bool = true
    @Published var isHeadphonesConnected: Bool = false
    @Published var currentDestination: String?
    @Published var targetStopName: String?
    @Published var notificationDistance: Int = 2
    
    // éŸ³é »å¼•æ“
    private let speechSynthesizer = AVSpeechSynthesizer()
    private let audioSession = AVAudioSession.sharedInstance()
    private var audioPlayer: AVAudioPlayer?
    
    // èªéŸ³è¨­å®š
    private var _voiceLanguage: String = "zh-TW"
    private var _speechRate: Float = 0.5
    private var _speechVolume: Float = 1.0
    
    // é˜²é‡è¤‡æ’­å ±æ©Ÿåˆ¶ - é—œéµä¿®å¾©
    private var lastAnnouncementTime: Date?
    private var lastAnnouncementContent: String?
    private let minimumAnnouncementInterval: TimeInterval = 10.0 // æœ€å°‘é–“éš”10ç§’
    private var pendingSpeechQueue: [String] = []
    private var isSpeaking: Bool = false
    
    // ç›£æ§ç‹€æ…‹
    private var isMonitoring = false
    private var cancellables = Set<AnyCancellable>()
    
    // ç›®çš„åœ°è¨­å®š
    private var destinationRoute: String?
    private var destinationStop: String?
    private var hasNotifiedApproaching = false
    private var hasNotifiedArrival = false
    
    // èªéŸ³ç‹€æ…‹è¿½è¹¤
    private var speechQueue: DispatchQueue
    
    override init() {
        speechQueue = DispatchQueue(label: "com.off2go.speech", qos: .userInitiated)
        super.init()
        setupAudioSession()
        setupHeadphoneDetection()
        setupRemoteControl()
        setupSpeechSynthesizerDelegate()
        loadSettings()
    }
    
    // MARK: - èªéŸ³ç‹€æ…‹ç®¡ç†
    
    private func setupSpeechSynthesizerDelegate() {
        speechSynthesizer.delegate = self
    }
    
    // æª¢æŸ¥æ˜¯å¦å¯ä»¥æ’­å ±ï¼ˆé˜²é‡è¤‡æ ¸å¿ƒé‚è¼¯ï¼‰
    private func canAnnounce(_ content: String) -> Bool {
        let now = Date()
        
        // æª¢æŸ¥æ˜¯å¦æ­£åœ¨æ’­å ±
        if isSpeaking || speechSynthesizer.isSpeaking {
            print("ğŸ”‡ [Audio] æ­£åœ¨æ’­å ±ä¸­ï¼Œè·³éæ–°çš„æ’­å ±")
            return false
        }
        
        // æª¢æŸ¥æ˜¯å¦ç‚ºé‡è¤‡å…§å®¹
        if let lastContent = lastAnnouncementContent,
           lastContent == content {
            if let lastTime = lastAnnouncementTime,
               now.timeIntervalSince(lastTime) < minimumAnnouncementInterval {
                print("ğŸ”‡ [Audio] é‡è¤‡å…§å®¹ä¸”æ™‚é–“é–“éš”éçŸ­ï¼Œè·³éæ’­å ±: \(content)")
                return false
            }
        }
        
        // æª¢æŸ¥æ™‚é–“é–“éš”
        if let lastTime = lastAnnouncementTime,
           now.timeIntervalSince(lastTime) < 3.0 { // ä»»ä½•æ’­å ±é–“éš”è‡³å°‘3ç§’
            print("ğŸ”‡ [Audio] æ’­å ±é–“éš”éçŸ­ï¼Œè·³é")
            return false
        }
        
        return true
    }
    
    // æ›´æ–°æ’­å ±è¨˜éŒ„
    private func updateAnnouncementHistory(_ content: String) {
        lastAnnouncementTime = Date()
        lastAnnouncementContent = content
        isSpeaking = true
    }
    
    // MARK: - èªéŸ³æ’­å ±ä¿®å¾©ç‰ˆæœ¬
    
    private func speakMessage(_ message: String, priority: SpeechPriority) {
        // ä½¿ç”¨å°ˆç”¨éšŠåˆ—è™•ç†èªéŸ³æ’­å ±
        speechQueue.async { [weak self] in
            guard let self = self else { return }
            
            // ä¸»ç·šç¨‹æª¢æŸ¥æ’­å ±æ¢ä»¶
            DispatchQueue.main.sync {
                // æª¢æŸ¥åŸºæœ¬æ¢ä»¶
                guard self.isAudioEnabled && (self.isHeadphonesConnected || self.allowSpeakerOutput()) else {
                    print("ğŸ”‡ [Audio] æ’­å ±æ¢ä»¶ä¸æ»¿è¶³")
                    return
                }
                
                // æª¢æŸ¥æ˜¯å¦å¯ä»¥æ’­å ±
                guard self.canAnnounce(message) else {
                    return
                }
                
                print("ğŸ¤ [Audio] æº–å‚™æ’­å ±: \(message)")
                
                // æ ¹æ“šå„ªå…ˆç´šè™•ç†
                switch priority {
                case .urgent:
                    // ç·Šæ€¥æƒ…æ³ï¼šåœæ­¢ç•¶å‰æ’­å ±
                    if self.speechSynthesizer.isSpeaking {
                        self.speechSynthesizer.stopSpeaking(at: .immediate)
                    }
                    self.performSpeech(message, priority: priority)
                    
                case .high:
                    // é«˜å„ªå…ˆç´šï¼šåœæ­¢ç•¶å‰æ’­å ±
                    if self.speechSynthesizer.isSpeaking {
                        self.speechSynthesizer.stopSpeaking(at: .word)
                    }
                    // å»¶é²ä¸€é»ç¢ºä¿åœæ­¢å®Œæˆ
                    DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                        self.performSpeech(message, priority: priority)
                    }
                    
                case .normal:
                    // æ™®é€šå„ªå…ˆç´šï¼šç­‰å¾…ç•¶å‰æ’­å ±å®Œæˆæˆ–ç›´æ¥æ’­å ±
                    if self.speechSynthesizer.isSpeaking {
                        self.pendingSpeechQueue.append(message)
                        print("ğŸ¤ [Audio] åŠ å…¥æ’­å ±éšŠåˆ—: \(message)")
                    } else {
                        self.performSpeech(message, priority: priority)
                    }
                }
            }
        }
    }
    
    private func performSpeech(_ message: String, priority: SpeechPriority) {
        updateAnnouncementHistory(message)
        
        let utterance = AVSpeechUtterance(string: message)
        utterance.voice = AVSpeechSynthesisVoice(language: _voiceLanguage)
        
        // æ ¹æ“šå„ªå…ˆç´šèª¿æ•´èªéŸ³åƒæ•¸
        switch priority {
        case .urgent:
            utterance.rate = 0.4
            utterance.volume = 1.0
            utterance.preUtteranceDelay = 0.1
        case .high:
            utterance.rate = 0.45
            utterance.volume = 0.9
            utterance.preUtteranceDelay = 0.2
        case .normal:
            utterance.rate = _speechRate
            utterance.volume = _speechVolume
            utterance.preUtteranceDelay = 0.5
        }
        
        speechSynthesizer.speak(utterance)
        print("ğŸ¤ [Audio] é–‹å§‹æ’­å ±: \(message)")
    }
    
    // MARK: - ç«™é»é€šçŸ¥ä¿®å¾©ç‰ˆæœ¬
    
    func checkStationProximity(currentStops: [BusStop.Stop], nearestStopIndex: Int?) {
        // åªåœ¨ç›£æ§ä¸”éŸ³é »å•Ÿç”¨æ™‚åŸ·è¡Œ
        guard isMonitoring,
              isAudioEnabled,
              let targetStop = destinationStop,
              let nearestIndex = nearestStopIndex,
              nearestIndex < currentStops.count else {
            return
        }
        
        let currentStop = currentStops[nearestIndex]
        let remainingStops = calculateRemainingStops(
            currentStops: currentStops,
            currentIndex: nearestIndex,
            targetStopName: targetStop
        )
        
        // é˜²é‡è¤‡é€šçŸ¥çš„é—œéµæª¢æŸ¥
        let currentStopID = currentStop.StopID
        let proximityKey = "proximity_\(currentStopID)_\(remainingStops)"
        
        // æª¢æŸ¥æ˜¯å¦å·²ç¶“ç‚ºé€™å€‹ä½ç½®é€šçŸ¥é
        if hasRecentlyNotified(key: proximityKey) {
            return
        }
        
        // æª¢æŸ¥æ˜¯å¦éœ€è¦æå‰é€šçŸ¥
        if remainingStops == notificationDistance && !hasNotifiedApproaching {
            announceApproachingDestination(remainingStops: remainingStops)
            hasNotifiedApproaching = true
            recordNotification(key: proximityKey)
        }
        
        // æª¢æŸ¥æ˜¯å¦åˆ°é”ç›®çš„åœ°
        if currentStop.StopName.Zh_tw.contains(targetStop) && !hasNotifiedArrival {
            announceArrivalAtDestination()
            hasNotifiedArrival = true
            recordNotification(key: "arrival_\(currentStopID)")
        }
    }
    
    // é€šçŸ¥è¨˜éŒ„ç®¡ç†
    private var notificationHistory: [String: Date] = [:]
    
    private func hasRecentlyNotified(key: String) -> Bool {
        if let lastTime = notificationHistory[key] {
            return Date().timeIntervalSince(lastTime) < 30.0 // 30ç§’å…§ä¸é‡è¤‡
        }
        return false
    }
    
    private func recordNotification(key: String) {
        notificationHistory[key] = Date()
        
        // æ¸…ç†éæœŸè¨˜éŒ„
        let cutoffTime = Date().addingTimeInterval(-300) // 5åˆ†é˜å‰
        notificationHistory = notificationHistory.filter { $0.value > cutoffTime }
    }
    
    // MARK: - ä¿®å¾©å¾Œçš„é€šçŸ¥æ–¹æ³•
    
    private func announceDestinationSet(routeName: String, stopName: String) {
        let message = "ç›®çš„åœ°å·²è¨­å®šç‚º\(stopName)ï¼Œå°‡åœ¨å‰\(notificationDistance)ç«™æé†’æ‚¨"
        speakMessage(message, priority: .high)
    }
    
    private func announceDestinationCleared() {
        let message = "ç›®çš„åœ°å·²å–æ¶ˆ"
        speakMessage(message, priority: .normal)
    }
    
    private func announceApproachingDestination(remainingStops: Int) {
        guard let targetStop = destinationStop else { return }
        let message = "æé†’æ‚¨ï¼Œå†\(remainingStops)ç«™å°±åˆ°\(targetStop)ï¼Œè«‹æº–å‚™ä¸‹è»Š"
        
        speakMessage(message, priority: .high)
        playNotificationSound()
        updateNowPlayingInfo(with: "å³å°‡åˆ°ç«™æé†’")
    }
    
    private func announceArrivalAtDestination() {
        guard let targetStop = destinationStop else { return }
        let message = "\(targetStop)åˆ°äº†ï¼Œè«‹æº–å‚™ä¸‹è»Š"
        
        speakMessage(message, priority: .urgent)
        playNotificationSound()
        updateNowPlayingInfo(with: "å·²åˆ°é”ç›®çš„åœ°")
        
        // å»¶é²æ¸…é™¤ç›®çš„åœ°
        DispatchQueue.main.asyncAfter(deadline: .now() + 5) {
            self.clearDestination()
        }
    }
    
    func announceStationInfo(stopName: String, arrivalTime: String? = nil) {
        // é¿å…èˆ‡ç«™é»æ¥è¿‘é€šçŸ¥é‡è¤‡
        let baseMessage = "å³å°‡åˆ°é”\(stopName)"
        var message = baseMessage
        
        if let time = arrivalTime, !time.isEmpty, time != baseMessage {
            message += "ï¼Œ\(time)"
        }
        
        // ä½¿ç”¨è¼ƒä½å„ªå…ˆç´šï¼Œé¿å…å¹²æ“¾é‡è¦é€šçŸ¥
        speakMessage(message, priority: .normal)
    }
    
    // MARK: - ç›®çš„åœ°è¨­å®š
    
    func setDestination(_ routeName: String, stopName: String) {
        // é¿å…é‡è¤‡è¨­å®š
        if destinationRoute == routeName && destinationStop == stopName {
            print("ğŸ¯ [Audio] ç›®çš„åœ°æœªè®Šæ›´ï¼Œè·³éè¨­å®š")
            return
        }
        
        destinationRoute = routeName
        destinationStop = stopName
        targetStopName = stopName
        currentDestination = "\(routeName) - \(stopName)"
        
        // é‡ç½®é€šçŸ¥ç‹€æ…‹
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        notificationHistory.removeAll() // æ¸…é™¤é€šçŸ¥æ­·å²
        
        startMonitoring()
        announceDestinationSet(routeName: routeName, stopName: stopName)
        
        print("ğŸ¯ [Audio] è¨­å®šç›®çš„åœ°: \(routeName) - \(stopName)")
    }
    
    func clearDestination() {
        destinationRoute = nil
        destinationStop = nil
        targetStopName = nil
        currentDestination = nil
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        notificationHistory.removeAll()
        
        stopMonitoring()
        announceDestinationCleared()
        
        print("ğŸ—‘ï¸ [Audio] å·²æ¸…é™¤ç›®çš„åœ°")
    }
    
    // MARK: - å…¶ä»–åŸæœ‰æ–¹æ³•ä¿æŒä¸è®Š
    
    private func setupAudioSession() {
        do {
            try audioSession.setCategory(.playback,
                                       mode: .spokenAudio,
                                       options: [.duckOthers, .allowAirPlay, .allowBluetooth])
            try audioSession.setActive(true)
            print("âœ… [Audio] éŸ³é »æœƒè©±è¨­å®šæˆåŠŸ")
        } catch {
            print("âŒ [Audio] éŸ³é »æœƒè©±è¨­å®šå¤±æ•—: \(error.localizedDescription)")
        }
    }
    
    private func setupHeadphoneDetection() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(audioRouteChanged),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        checkHeadphoneConnection()
    }
    
    @objc private func audioRouteChanged(notification: Notification) {
        checkHeadphoneConnection()
    }
    
    private func checkHeadphoneConnection() {
        let currentRoute = audioSession.currentRoute
        var headphonesConnected = false
        
        for output in currentRoute.outputs {
            switch output.portType {
            case .headphones, .bluetoothA2DP, .bluetoothHFP, .bluetoothLE:
                headphonesConnected = true
                break
            default:
                break
            }
        }
        
        DispatchQueue.main.async {
            self.isHeadphonesConnected = headphonesConnected
        }
    }
    
    private func setupRemoteControl() {
        UIApplication.shared.beginReceivingRemoteControlEvents()
        let commandCenter = MPRemoteCommandCenter.shared()
        
        commandCenter.playCommand.addTarget { [weak self] event in
            self?.toggleAudioNotifications()
            return .success
        }
        
        commandCenter.pauseCommand.addTarget { [weak self] event in
            self?.toggleAudioNotifications()
            return .success
        }
    }
    
    private func startMonitoring() {
        guard !isMonitoring else { return }
        isMonitoring = true
        updateNowPlayingInfo()
        print("â–¶ï¸ [Audio] é–‹å§‹éŸ³é »ç›£æ§")
    }
    
    private func stopMonitoring() {
        isMonitoring = false
        print("â¹ï¸ [Audio] åœæ­¢éŸ³é »ç›£æ§")
    }
    
    private func calculateRemainingStops(currentStops: [BusStop.Stop], currentIndex: Int, targetStopName: String) -> Int {
        for (index, stop) in currentStops.enumerated() {
            if index > currentIndex && stop.StopName.Zh_tw.contains(targetStopName) {
                return index - currentIndex
            }
        }
        return -1
    }
    
    private func playNotificationSound() {
        guard let soundURL = Bundle.main.url(forResource: "notification", withExtension: "mp3") else {
            playSystemSound()
            return
        }
        
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: soundURL)
            audioPlayer?.volume = 0.7
            audioPlayer?.play()
        } catch {
            playSystemSound()
        }
    }
    
    private func playSystemSound() {
        AudioServicesPlaySystemSound(1007)
    }
    
    private func updateNowPlayingInfo(with status: String = "ç›£æ§ä¸­") {
        var nowPlayingInfo = [String: Any]()
        
        if let destination = currentDestination {
            nowPlayingInfo[MPMediaItemPropertyTitle] = "Off2Go åˆ°ç«™æé†’"
            nowPlayingInfo[MPMediaItemPropertyArtist] = destination
            nowPlayingInfo[MPMediaItemPropertyAlbumTitle] = status
        } else {
            nowPlayingInfo[MPMediaItemPropertyTitle] = "Off2Go"
            nowPlayingInfo[MPMediaItemPropertyArtist] = "å…¬è»Šåˆ°ç«™æé†’"
            nowPlayingInfo[MPMediaItemPropertyAlbumTitle] = "å¾…æ©Ÿä¸­"
        }
        
        nowPlayingInfo[MPNowPlayingInfoPropertyIsLiveStream] = true
        nowPlayingInfo[MPMediaItemPropertyPlaybackDuration] = 0
        nowPlayingInfo[MPNowPlayingInfoPropertyPlaybackRate] = isMonitoring ? 1.0 : 0.0
        
        MPNowPlayingInfoCenter.default().nowPlayingInfo = nowPlayingInfo
    }
    
    private func allowSpeakerOutput() -> Bool {
        return UserDefaults.standard.bool(forKey: "allowSpeakerOutput")
    }
    
    // MARK: - è¨­å®šæ§åˆ¶
    
    func toggleAudioNotifications() {
        isAudioEnabled.toggle()
        saveSettings()
        
        let message = isAudioEnabled ? "èªéŸ³æé†’é–‹å•Ÿ" : "èªéŸ³æé†’é—œé–‰"
        speakMessage(message, priority: .normal)
        updateNowPlayingInfo()
    }
    
    func increaseNotificationDistance() {
        notificationDistance = min(notificationDistance + 1, 5)
        saveSettings()
        
        let message = "æé†’è·é›¢å·²èª¿æ•´ç‚ºå‰\(notificationDistance)ç«™"
        speakMessage(message, priority: .normal)
    }
    
    func decreaseNotificationDistance() {
        notificationDistance = max(notificationDistance - 1, 1)
        saveSettings()
        
        let message = "æé†’è·é›¢å·²èª¿æ•´ç‚ºå‰\(notificationDistance)ç«™"
        speakMessage(message, priority: .normal)
    }
    
    func setSpeechRate(_ rate: Float) {
        _speechRate = max(0.1, min(1.0, rate))
        saveSettings()
    }
    
    func setSpeechVolume(_ volume: Float) {
        _speechVolume = max(0.1, min(1.0, volume))
        saveSettings()
    }
    
    func setVoiceLanguage(_ language: String) {
        _voiceLanguage = language
        saveSettings()
    }
    
    // MARK: - èªéŸ³è¨­å®šå±¬æ€§
    
    var voiceLanguage: String { _voiceLanguage }
    var speechRate: Float { _speechRate }
    var speechVolume: Float { _speechVolume }
    
    // MARK: - è¨­å®šæŒä¹…åŒ–
    
    private func saveSettings() {
        UserDefaults.standard.set(isAudioEnabled, forKey: "audioEnabled")
        UserDefaults.standard.set(notificationDistance, forKey: "notificationDistance")
        UserDefaults.standard.set(_speechRate, forKey: "speechRate")
        UserDefaults.standard.set(_speechVolume, forKey: "speechVolume")
        UserDefaults.standard.set(_voiceLanguage, forKey: "voiceLanguage")
    }
    
    private func loadSettings() {
        isAudioEnabled = UserDefaults.standard.bool(forKey: "audioEnabled")
        notificationDistance = UserDefaults.standard.integer(forKey: "notificationDistance")
        _speechRate = UserDefaults.standard.float(forKey: "speechRate")
        _speechVolume = UserDefaults.standard.float(forKey: "speechVolume")
        _voiceLanguage = UserDefaults.standard.string(forKey: "voiceLanguage") ?? "zh-TW"
        
        if notificationDistance == 0 { notificationDistance = 2 }
        if _speechRate == 0 { _speechRate = 0.5 }
        if _speechVolume == 0 { _speechVolume = 1.0 }
    }
    
    // MARK: - é‡ç½®é€šçŸ¥ç‹€æ…‹
    
    func resetNotificationStatus() {
        // æ¸…ç†æ’­å ±æ­·å²
        lastAnnouncementTime = nil
        lastAnnouncementContent = nil
        pendingSpeechQueue.removeAll()
        notificationHistory.removeAll()
        
        // é‡ç½®ç›®çš„åœ°é€šçŸ¥ç‹€æ…‹
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        // åœæ­¢ç•¶å‰æ’­å ±
        if speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        isSpeaking = false
        
        print("ğŸ”„ [Audio] å·²é‡ç½®éŸ³é »é€šçŸ¥ç‹€æ…‹")
    }
    
    deinit {
        NotificationCenter.default.removeObserver(self)
        speechSynthesizer.stopSpeaking(at: .immediate)
        UIApplication.shared.endReceivingRemoteControlEvents()
    }
}

// MARK: - AVSpeechSynthesizerDelegate

extension AudioNotificationService: AVSpeechSynthesizerDelegate {
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        print("ğŸ¤ [Audio] é–‹å§‹æ’­å ±: \(utterance.speechString)")
        isSpeaking = true
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        print("âœ… [Audio] æ’­å ±å®Œæˆ: \(utterance.speechString)")
        isSpeaking = false
        
        // è™•ç†å¾…æ’­å ±éšŠåˆ—
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
            self.processNextSpeechInQueue()
        }
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        print("ğŸ›‘ [Audio] æ’­å ±è¢«å–æ¶ˆ: \(utterance.speechString)")
        isSpeaking = false
        
        // è™•ç†å¾…æ’­å ±éšŠåˆ—
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.2) {
            self.processNextSpeechInQueue()
        }
    }
    
    private func processNextSpeechInQueue() {
        guard !pendingSpeechQueue.isEmpty, !isSpeaking else { return }
        
        let nextMessage = pendingSpeechQueue.removeFirst()
        print("ğŸ¤ [Audio] æ’­å ±éšŠåˆ—ä¸­çš„ä¸‹ä¸€å€‹: \(nextMessage)")
        performSpeech(nextMessage, priority: .normal)
    }
}

// MARK: - èªéŸ³å„ªå…ˆç´šæšèˆ‰

private enum SpeechPriority {
    case normal, high, urgent
}
