//
//  AudioNotificationService.swift - ç°¡åŒ–å„ªåŒ–ç‰ˆ
//  Off2Go
//
//  é‡æ§‹ç‰ˆæœ¬ï¼šç°¡åŒ–æ¶æ§‹ï¼Œä¿®å¾©èƒŒæ™¯èªéŸ³å•é¡Œ
//

import Foundation
import AVFoundation
import MediaPlayer
import Combine
import CoreLocation

class AudioNotificationService: NSObject, ObservableObject {
    static let shared = AudioNotificationService()
    
    // MARK: - æ ¸å¿ƒç‹€æ…‹
    @Published var isAudioEnabled: Bool = true
    @Published var isHeadphonesConnected: Bool = false
    @Published var currentDestination: String?
    @Published var targetStopName: String?
    
    // MARK: - éŸ³é »æ ¸å¿ƒ
    private let speechSynthesizer = AVSpeechSynthesizer()
    private let audioSession = AVAudioSession.sharedInstance()
    
    // MARK: - è¨­å®š
    private var _voiceLanguage: String = "zh-TW"
    private var _speechRate: Float = 0.5
    private var _speechVolume: Float = 1.0
    private var notificationDistance: Int = 2
    
    // MARK: - é˜²é‡è¤‡æ©Ÿåˆ¶
    private var lastAnnouncementTime: [String: Date] = [:]
    private let minimumAnnouncementInterval: TimeInterval = 5.0
    private var isSpeaking: Bool = false
    
    // MARK: - ç›®çš„åœ°è¿½è¹¤
    private var destinationRoute: String?
    private var destinationStop: String?
    private var hasNotifiedApproaching = false
    private var hasNotifiedArrival = false
    
    // MARK: - ä½ç½®è¿½è¹¤
    private var locationTrackingTimer: Timer?
    private var isTrackingActive = false
    
    override init() {
        super.init()
        setupAudioSession()
        setupHeadphoneDetection()
        setupSpeechDelegate()
        loadSettings()
        print("ğŸ”Š [Audio] AudioNotificationService åˆå§‹åŒ–å®Œæˆ")
    }
    
    // MARK: - ç°¡åŒ–çš„éŸ³é »è¨­å®š
    
    private func setupAudioSession() {
        print("ğŸ”Š [Audio] è¨­å®šéŸ³é »æœƒè©±...")
        
        do {
            let audioSession = AVAudioSession.sharedInstance()
            
            // æª¢æŸ¥è¨­å‚™æ˜¯å¦æ”¯æ´éŸ³é »æ’­æ”¾
            let availableCategories = audioSession.availableCategories
            print("ğŸ“± [Audio] å¯ç”¨éŸ³é »é¡åˆ¥: \(availableCategories)")
            
            // ä½¿ç”¨æœ€ç›¸å®¹çš„è¨­å®š - æ”¹ç‚º playAndRecord ä»¥æ”¯æ´èƒŒæ™¯æ’­æ”¾
            if availableCategories.contains(.playAndRecord) {
                try audioSession.setCategory(
                    .playAndRecord,
                    mode: .spokenAudio,
                    options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP, .mixWithOthers]
                )
            } else if availableCategories.contains(.playback) {
                try audioSession.setCategory(
                    .playback,
                    mode: .spokenAudio,
                    options: [.allowBluetooth, .allowBluetoothA2DP, .mixWithOthers]
                )
            } else {
                // å¾Œå‚™é¸é …
                try audioSession.setCategory(.ambient)
            }
            
            // è¨­å®šéŸ³é »å“è³ª
            try audioSession.setPreferredSampleRate(44100.0)
            try audioSession.setPreferredIOBufferDuration(0.005)
            
            // å•Ÿç”¨æœƒè©±
            try audioSession.setActive(true, options: [])
            print("âœ… [Audio] éŸ³é »æœƒè©±è¨­å®šæˆåŠŸ")
            
        } catch let error as NSError {
            print("âŒ [Audio] éŸ³é »æœƒè©±è¨­å®šå¤±æ•—: \(error.localizedDescription)")
            print("   éŒ¯èª¤ä»£ç¢¼: \(error.code)")
            print("   éŒ¯èª¤åŸŸ: \(error.domain)")
            
            // å˜—è©¦ç°¡åŒ–è¨­å®š
            simplifiedAudioSetup()
        }
    }
    
    
    
    private func simplifiedAudioSetup() {
        print("ğŸ”„ [Audio] å˜—è©¦ç°¡åŒ–éŸ³é »è¨­å®š...")
        
        do {
            let audioSession = AVAudioSession.sharedInstance()
            
            // æœ€ç°¡å–®çš„è¨­å®š
            try audioSession.setCategory(.ambient)
            try audioSession.setActive(true)
            print("âœ… [Audio] ç°¡åŒ–éŸ³é »è¨­å®šæˆåŠŸ")
            
        } catch {
            print("âŒ [Audio] ç°¡åŒ–éŸ³é »è¨­å®šä¹Ÿå¤±æ•—: \(error.localizedDescription)")
            // ä½¿ç”¨ç³»çµ±èªéŸ³æ’­å ±ä½œç‚ºå¾Œå‚™
            useFallbackSpeech()
        }
    }
    
    private func useFallbackSpeech() {
        print("ğŸ”„ [Audio] ä½¿ç”¨å¾Œå‚™èªéŸ³æ’­å ±æ–¹æ¡ˆ")
        // ä¸ä¾è³´éŸ³é »æœƒè©±çš„èªéŸ³æ’­å ±å°‡åœ¨ executeSpeech ä¸­è™•ç†
    }
    
    private func fallbackAudioSetup() {
        do {
            try audioSession.setCategory(.ambient)
            try audioSession.setActive(true)
            print("âœ… [Audio] å‚™ç”¨éŸ³é »è¨­å®šæˆåŠŸ")
        } catch {
            print("âŒ [Audio] å‚™ç”¨éŸ³é »è¨­å®šå¤±æ•—: \(error.localizedDescription)")
        }
    }
    
    // MARK: - çµ±ä¸€çš„èªéŸ³æ’­å ±æ–¹æ³•
    
    /// ç­‰è»Šæé†’ - æœ€é«˜å„ªå…ˆç´š
    func announceWaitingBusAlert(_ message: String) {
        print("ğŸš¨ [Audio] ç­‰è»Šæé†’: \(message)")
        
        // ç«‹å³æ’­æ”¾ç³»çµ±æç¤ºéŸ³
        AudioServicesPlaySystemSound(1007) // é‡è¦æé†’éŸ³
        
        // ç¢ºä¿éŸ³é »æœƒè©±æº–å‚™å°±ç·’
        ensureAudioSessionForSpeech { [weak self] success in
            guard let self = self else { return }
            
            DispatchQueue.main.async {
                // ç„¡è«–éŸ³é »æœƒè©±æ˜¯å¦æˆåŠŸï¼Œéƒ½å˜—è©¦æ’­å ±
                self.performSpeech(message, priority: .urgent, category: "waiting")
                
                // å¦‚æœç¬¬ä¸€æ¬¡å¤±æ•—ï¼Œå»¶é²å¾Œå†è©¦ä¸€æ¬¡
                DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                    if !self.speechSynthesizer.isSpeaking {
                        print("ğŸ”„ [Audio] èªéŸ³æ’­å ±å¯èƒ½å¤±æ•—ï¼Œé‡è©¦...")
                        
                        // å†æ¬¡å˜—è©¦éŸ³é »è¨­å®š
                        do {
                            try AVAudioSession.sharedInstance().setCategory(.playback, mode: .spokenAudio, options: [.duckOthers])
                            try AVAudioSession.sharedInstance().setActive(true)
                            
                            // é‡æ–°æ’­å ±
                            self.performSpeech(message, priority: .urgent, category: "waiting_retry")
                        } catch {
                            print("âŒ [Audio] é‡è©¦éŸ³é »è¨­å®šå¤±æ•—: \(error.localizedDescription)")
                            
                            // æœ€å¾Œæ‰‹æ®µï¼šä½¿ç”¨æœ€ç°¡å–®çš„è¨­å®š
                            do {
                                try AVAudioSession.sharedInstance().setCategory(.ambient)
                                try AVAudioSession.sharedInstance().setActive(true)
                                self.performSpeech(message, priority: .urgent, category: "waiting_final")
                            } catch {
                                print("âŒ [Audio] æ‰€æœ‰éŸ³é »è¨­å®šéƒ½å¤±æ•—")
                            }
                        }
                    }
                }
            }
        }
    }
    
    /// åˆ°ç«™æé†’ - é«˜å„ªå…ˆç´š
    func announceArrivalAlert(_ message: String) {
        print("ğŸ¯ [Audio] åˆ°ç«™æé†’: \(message)")
        performSpeech(message, priority: .high, category: "arrival")
    }
    
    /// æ¥è¿‘ç›®çš„åœ° - é«˜å„ªå…ˆç´š
    func announceApproachingDestination(_ message: String) {
        print("ğŸ”” [Audio] æ¥è¿‘æé†’: \(message)")
        performSpeech(message, priority: .high, category: "approaching")
    }
    
    /// ä¸€èˆ¬ç«™é»è³‡è¨Š - æ™®é€šå„ªå…ˆç´š
    func announceStationInfo(stopName: String, arrivalTime: String? = nil) {
        let message = buildStationMessage(stopName: stopName, arrivalTime: arrivalTime)
        print("â„¹ï¸ [Audio] ç«™é»è³‡è¨Š: \(message)")
        performSpeech(message, priority: .normal, category: "station")
    }
    
    /// æ¸¬è©¦èªéŸ³æ’­å ±
    func testVoicePlayback(_ message: String) {
        print("ğŸ§ª [Audio] æ¸¬è©¦æ’­å ±: \(message)")
        performSpeech(message, priority: .test, category: "test")
    }
    
    // MARK: - æ ¸å¿ƒèªéŸ³æ’­å ±é‚è¼¯
    
    private func performSpeech(_ message: String, priority: SpeechPriority, category: String) {
        guard isAudioEnabled || priority == .test || priority == .urgent else {
            print("ğŸ”‡ [Audio] èªéŸ³å·²é—œé–‰ï¼Œè·³éæ’­å ±")
            return
        }
        
        // æª¢æŸ¥é‡è¤‡æ’­å ±
        if !canAnnounce(message, category: category, priority: priority) {
            return
        }
        
        // ç¢ºä¿éŸ³é »æœƒè©±æ´»èº
        ensureAudioSessionActive()
        
        // åœæ­¢ç•¶å‰æ’­å ±ï¼ˆå¦‚æœæ˜¯æ›´é«˜å„ªå…ˆç´šï¼‰
        if priority.rawValue >= SpeechPriority.high.rawValue && speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        
        // æ’­æ”¾æç¤ºéŸ³ï¼ˆç·Šæ€¥æƒ…æ³ï¼‰
        if priority == .urgent {
            AudioServicesPlaySystemSound(1007) // é‡è¦æé†’éŸ³
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.executeSpeech(message, priority: priority, category: category)
            }
        } else {
            executeSpeech(message, priority: priority, category: category)
        }
    }
    
    private func executeSpeech(_ message: String, priority: SpeechPriority, category: String) {
        let utterance = AVSpeechUtterance(string: message)
        utterance.voice = AVSpeechSynthesisVoice(language: _voiceLanguage)
        
        // æ ¹æ“šå„ªå…ˆç´šè¨­å®šèªéŸ³åƒæ•¸
        switch priority {
        case .urgent:
            utterance.rate = 0.4
            utterance.volume = 1.0
            utterance.preUtteranceDelay = 0.1
        case .high:
            utterance.rate = 0.45
            utterance.volume = 0.9
            utterance.preUtteranceDelay = 0.2
        case .normal:
            utterance.rate = _speechRate
            utterance.volume = _speechVolume
            utterance.preUtteranceDelay = 0.3
        case .test:
            utterance.rate = 0.5
            utterance.volume = 1.0
            utterance.preUtteranceDelay = 0.1
        }
        
        // è¨˜éŒ„æ’­å ±æ­·å²
        updateAnnouncementHistory(message, category: category)
        
        // åœ¨æ’­å ±å‰å˜—è©¦ç¢ºä¿éŸ³é »æœƒè©±
        ensureAudioSessionForSpeech { [weak self] success in
            guard let self = self else { return }
            
            DispatchQueue.main.async {
                // ç„¡è«–éŸ³é »æœƒè©±æ˜¯å¦æˆåŠŸï¼Œéƒ½å˜—è©¦æ’­å ±
                self.speechSynthesizer.speak(utterance)
                self.isSpeaking = true
                print("ğŸ¤ [Audio] é–‹å§‹æ’­å ±: \(message)")
            }
        }
    }
    
    private func ensureAudioSessionForSpeech(completion: @escaping (Bool) -> Void) {
        DispatchQueue.global(qos: .userInitiated).async {
            do {
                let audioSession = AVAudioSession.sharedInstance()
                
                // æª¢æŸ¥ç•¶å‰ç‹€æ…‹
                let currentCategory = audioSession.category
                print("ğŸ” [Audio] ç•¶å‰éŸ³é »é¡åˆ¥: \(currentCategory)")
                
                // å¼·åˆ¶è¨­å®šç‚ºæ’­æ”¾é¡åˆ¥
                if currentCategory != .playAndRecord && currentCategory != .playback {
                    try audioSession.setCategory(
                        .playAndRecord,
                        mode: .spokenAudio,
                        options: [.defaultToSpeaker, .allowBluetooth, .allowBluetoothA2DP, .mixWithOthers]
                    )
                }
                
                // é‡æ–°å•Ÿç”¨æœƒè©±ï¼ˆé€™æœƒè¦†è“‹ä¹‹å‰çš„ç‹€æ…‹ï¼‰
                try audioSession.setActive(true, options: [])
                
                print("âœ… [Audio] èªéŸ³æ’­å ±éŸ³é »æœƒè©±æº–å‚™æˆåŠŸ")
                DispatchQueue.main.async {
                    completion(true)
                }
                
            } catch {
                print("âš ï¸ [Audio] èªéŸ³æ’­å ±éŸ³é »æœƒè©±æº–å‚™å¤±æ•—: \(error.localizedDescription)")
                
                // å˜—è©¦åŸºæœ¬è¨­å®š
                do {
                    try AVAudioSession.sharedInstance().setCategory(.ambient)
                    try AVAudioSession.sharedInstance().setActive(true)
                    print("âœ… [Audio] ä½¿ç”¨åŸºæœ¬éŸ³é »è¨­å®š")
                    DispatchQueue.main.async {
                        completion(true)
                    }
                } catch {
                    print("âŒ [Audio] åŸºæœ¬éŸ³é »è¨­å®šä¹Ÿå¤±æ•—: \(error.localizedDescription)")
                    DispatchQueue.main.async {
                        completion(false)
                    }
                }
            }
        }
    }
    
    // MARK: - é‡è¤‡æ’­å ±æª¢æŸ¥
    
    private func canAnnounce(_ content: String, category: String, priority: SpeechPriority) -> Bool {
        let key = "\(category)_\(content)"
        let now = Date()
        
        // ç·Šæ€¥å’Œæ¸¬è©¦æ’­å ±ç¸½æ˜¯å…è¨±
        if priority == .urgent || priority == .test {
            return true
        }
        
        // æª¢æŸ¥æ˜¯å¦æ­£åœ¨æ’­å ±
        if isSpeaking && priority.rawValue < SpeechPriority.high.rawValue {
            print("ğŸ”‡ [Audio] æ­£åœ¨æ’­å ±ä¸­ï¼Œè·³éä½å„ªå…ˆç´šå…§å®¹")
            return false
        }
        
        // æª¢æŸ¥é‡è¤‡é–“éš”
        if let lastTime = lastAnnouncementTime[key],
           now.timeIntervalSince(lastTime) < minimumAnnouncementInterval {
            print("ğŸ”‡ [Audio] é‡è¤‡å…§å®¹é–“éš”éçŸ­ï¼Œè·³éæ’­å ±")
            return false
        }
        
        return true
    }
    
    private func updateAnnouncementHistory(_ content: String, category: String) {
        let key = "\(category)_\(content)"
        lastAnnouncementTime[key] = Date()
    }
    
    // MARK: - éŸ³é »æœƒè©±ç®¡ç†
    
    private func ensureAudioSessionActive() {
        print("ğŸ” [Audio] æª¢æŸ¥éŸ³é »æœƒè©±ç‹€æ…‹")
    }
    
    // MARK: - ç›®çš„åœ°ç®¡ç†
    
    func setDestination(_ routeName: String, stopName: String) {
        print("ğŸ¯ [Audio] è¨­å®šç›®çš„åœ°: \(routeName) - \(stopName)")
        
        destinationRoute = routeName
        destinationStop = stopName
        targetStopName = stopName
        currentDestination = routeName.isEmpty ? stopName : "\(routeName) - \(stopName)"
        
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        startLocationTracking()
        
        let message = "ç›®çš„åœ°å·²è¨­å®šç‚º\(stopName)ï¼Œå°‡åœ¨æ¥è¿‘æ™‚æé†’æ‚¨"
        performSpeech(message, priority: .normal, category: "destination")
        
        updateNowPlayingInfo(with: "è¿½è¹¤ä¸­")
    }
    
    func clearDestination() {
        print("ğŸ—‘ï¸ [Audio] æ¸…é™¤ç›®çš„åœ°")
        
        let hadDestination = destinationRoute != nil || destinationStop != nil
        
        destinationRoute = nil
        destinationStop = nil
        targetStopName = nil
        currentDestination = nil
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        stopLocationTracking()
        
        if hadDestination {
            let message = "ç›®çš„åœ°å·²å–æ¶ˆ"
            performSpeech(message, priority: .normal, category: "destination")
        }
        
        updateNowPlayingInfo(with: "å¾…æ©Ÿä¸­")
    }
    
    // MARK: - ä½ç½®è¿½è¹¤
    
    private func startLocationTracking() {
        guard LocationService.shared.hasLocationPermission else {
            print("âš ï¸ [Audio] éœ€è¦ä½ç½®æ¬Šé™æ‰èƒ½é–‹å§‹è¿½è¹¤")
            return
        }
        
        stopLocationTracking()
        LocationService.shared.startUpdatingLocation()
        
        locationTrackingTimer = Timer.scheduledTimer(withTimeInterval: 15, repeats: true) { [weak self] _ in
            self?.checkLocationForDestination()
        }
        
        isTrackingActive = true
        print("ğŸ“ [Audio] å·²é–‹å§‹ä½ç½®è¿½è¹¤")
    }
    
    private func stopLocationTracking() {
        locationTrackingTimer?.invalidate()
        locationTrackingTimer = nil
        isTrackingActive = false
        LocationService.shared.stopUpdatingLocation()
        print("ğŸ›‘ [Audio] å·²åœæ­¢ä½ç½®è¿½è¹¤")
    }
    
    private func checkLocationForDestination() {
        guard let targetStop = destinationStop,
              let userLocation = LocationService.shared.currentLocation else {
            return
        }
        
        print("ğŸ“ [Audio] æª¢æŸ¥ä½ç½®ï¼šè·é›¢ç›®çš„åœ°è¨ˆç®—ä¸­...")
    }
    
    func checkDestinationProximity(currentStops: [BusStop.Stop], userLocation: CLLocation) {
        guard isTrackingActive,
              let targetStop = destinationStop else {
            return
        }
        
        guard let destinationStopData = currentStops.first(where: { $0.StopName.Zh_tw.contains(targetStop) }) else {
            return
        }
        
        let stopLocation = CLLocation(
            latitude: destinationStopData.StopPosition.PositionLat,
            longitude: destinationStopData.StopPosition.PositionLon
        )
        
        let distance = userLocation.distance(from: stopLocation)
        print("ğŸ“ [Audio] è·é›¢ç›®çš„åœ° \(Int(distance)) å…¬å°º")
        
        if distance <= 100 && !hasNotifiedArrival {
            announceArrivalAtDestination()
            hasNotifiedArrival = true
        } else if distance <= 300 && !hasNotifiedApproaching {
            announceApproachingDestination(distance: Int(distance))
            hasNotifiedApproaching = true
        }
    }
    
    private func announceApproachingDestination(distance: Int) {
        guard let targetStop = destinationStop else { return }
        let message = "æé†’æ‚¨ï¼Œå³å°‡åˆ°é”\(targetStop)ï¼Œè·é›¢ç´„\(distance)å…¬å°ºï¼Œè«‹æº–å‚™ä¸‹è»Š"
        announceApproachingDestination(message)
        updateNowPlayingInfo(with: "å³å°‡åˆ°ç«™")
    }
    
    private func announceArrivalAtDestination() {
        guard let targetStop = destinationStop else { return }
        let message = "\(targetStop)åˆ°äº†ï¼Œè«‹æº–å‚™ä¸‹è»Š"
        announceArrivalAlert(message)
        updateNowPlayingInfo(with: "å·²åˆ°é”")
    }
    
    // MARK: - éŸ³é »è¨­å®šæ–¹æ³•
    
    func toggleAudioNotifications() {
        isAudioEnabled.toggle()
        saveSettings()
        
        let message = isAudioEnabled ? "èªéŸ³æé†’é–‹å•Ÿ" : "èªéŸ³æé†’é—œé–‰"
        performSpeech(message, priority: .normal, category: "settings")
        updateNowPlayingInfo()
    }
    
    func setSpeechRate(_ rate: Float) {
        _speechRate = max(0.1, min(1.0, rate))
        saveSettings()
    }
    
    func setSpeechVolume(_ volume: Float) {
        _speechVolume = max(0.1, min(1.0, volume))
        saveSettings()
    }
    
    func setVoiceLanguage(_ language: String) {
        _voiceLanguage = language
        saveSettings()
    }
    
    // MARK: - è¼”åŠ©æ–¹æ³•
    
    private func buildStationMessage(stopName: String, arrivalTime: String?) -> String {
        var message = "å³å°‡åˆ°é”\(stopName)"
        
        if let time = arrivalTime, !time.isEmpty, time != message {
            message += "ï¼Œ\(time)"
        }
        
        return message
    }
    
    private func setupHeadphoneDetection() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(audioRouteChanged),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        checkHeadphoneConnection()
    }
    
    @objc private func audioRouteChanged(notification: Notification) {
        checkHeadphoneConnection()
    }
    
    private func checkHeadphoneConnection() {
        let currentRoute = audioSession.currentRoute
        var headphonesConnected = false
        
        for output in currentRoute.outputs {
            switch output.portType {
            case .headphones, .bluetoothA2DP, .bluetoothHFP, .bluetoothLE:
                headphonesConnected = true
                break
            default:
                break
            }
        }
        
        DispatchQueue.main.async {
            self.isHeadphonesConnected = headphonesConnected
        }
    }
    
    private func setupSpeechDelegate() {
        speechSynthesizer.delegate = self
    }
    
    private func updateNowPlayingInfo(with status: String = "å¾…æ©Ÿä¸­") {
        var nowPlayingInfo = [String: Any]()
        
        if let destination = currentDestination {
            nowPlayingInfo[MPMediaItemPropertyTitle] = "Off2Go åˆ°ç«™æé†’"
            nowPlayingInfo[MPMediaItemPropertyArtist] = destination
            nowPlayingInfo[MPMediaItemPropertyAlbumTitle] = status
        } else {
            nowPlayingInfo[MPMediaItemPropertyTitle] = "Off2Go"
            nowPlayingInfo[MPMediaItemPropertyArtist] = "å…¬è»Šåˆ°ç«™æé†’"
            nowPlayingInfo[MPMediaItemPropertyAlbumTitle] = status
        }
        
        nowPlayingInfo[MPNowPlayingInfoPropertyIsLiveStream] = true
        nowPlayingInfo[MPNowPlayingInfoPropertyPlaybackRate] = isTrackingActive ? 1.0 : 0.0
        
        MPNowPlayingInfoCenter.default().nowPlayingInfo = nowPlayingInfo
    }
    
    // MARK: - æŒä¹…åŒ–
    
    private func saveSettings() {
        UserDefaults.standard.set(isAudioEnabled, forKey: "audioEnabled")
        UserDefaults.standard.set(notificationDistance, forKey: "notificationDistance")
        UserDefaults.standard.set(_speechRate, forKey: "speechRate")
        UserDefaults.standard.set(_speechVolume, forKey: "speechVolume")
        UserDefaults.standard.set(_voiceLanguage, forKey: "voiceLanguage")
    }
    
    private func loadSettings() {
        isAudioEnabled = UserDefaults.standard.bool(forKey: "audioEnabled")
        if !UserDefaults.standard.objectExists(forKey: "audioEnabled") {
            isAudioEnabled = true // é è¨­é–‹å•Ÿ
        }
        
        notificationDistance = UserDefaults.standard.integer(forKey: "notificationDistance")
        _speechRate = UserDefaults.standard.float(forKey: "speechRate")
        _speechVolume = UserDefaults.standard.float(forKey: "speechVolume")
        _voiceLanguage = UserDefaults.standard.string(forKey: "voiceLanguage") ?? "zh-TW"
        
        if notificationDistance == 0 { notificationDistance = 2 }
        if _speechRate == 0 { _speechRate = 0.5 }
        if _speechVolume == 0 { _speechVolume = 1.0 }
    }
    
    func resetNotificationStatus() {
        lastAnnouncementTime.removeAll()
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        if speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        isSpeaking = false
        
        print("ğŸ”„ [Audio] å·²é‡ç½®éŸ³é »é€šçŸ¥ç‹€æ…‹")
    }
    
    // MARK: - å±¬æ€§è¨ªå•å™¨
    
    var voiceLanguage: String { _voiceLanguage }
    var speechRate: Float { _speechRate }
    var speechVolume: Float { _speechVolume }
    
    deinit {
        stopLocationTracking()
        NotificationCenter.default.removeObserver(self)
        speechSynthesizer.stopSpeaking(at: .immediate)
    }
}

// MARK: - AVSpeechSynthesizerDelegate

extension AudioNotificationService: AVSpeechSynthesizerDelegate {
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        print("ğŸ¤ [Audio] é–‹å§‹æ’­å ±: \(utterance.speechString)")
        isSpeaking = true
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        print("âœ… [Audio] æ’­å ±å®Œæˆ: \(utterance.speechString)")
        isSpeaking = false
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        print("ğŸ›‘ [Audio] æ’­å ±è¢«å–æ¶ˆ: \(utterance.speechString)")
        isSpeaking = false
    }
}

// MARK: - èªéŸ³å„ªå…ˆç´š

private enum SpeechPriority: Int, CaseIterable {
    case normal = 1
    case high = 2
    case urgent = 3
    case test = 4
}

// MARK: - UserDefaults æ“´å±•

extension UserDefaults {
    func objectExists(forKey key: String) -> Bool {
        return object(forKey: key) != nil
    }
}
