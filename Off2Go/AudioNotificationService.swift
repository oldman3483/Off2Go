//
//  AudioNotificationService.swift - éŸ³é‡æ¢å¾©å„ªåŒ–ç‰ˆ
//  Off2Go
//
//  ä¿®å¾©ï¼šé¿å…è¨­å®šç­‰è»Šæé†’æ™‚ç«‹å³å½±éŸ¿éŸ³æ¨‚éŸ³é‡
//

import Foundation
import AVFoundation
import MediaPlayer
import Combine
import CoreLocation

class AudioNotificationService: NSObject, ObservableObject, AVSpeechSynthesizerDelegate {
    static let shared = AudioNotificationService()
    
    // MARK: - æ ¸å¿ƒç‹€æ…‹
    @Published var isAudioEnabled: Bool = true
    @Published var isHeadphonesConnected: Bool = false
    @Published var currentDestination: String?
    @Published var targetStopName: String?
    
    // MARK: - æ™ºæ…§éŸ³é »è¨­å®š
    @Published var smartVolumeEnabled: Bool = true
    @Published var videoModeEnabled: Bool = true
    @Published var duckingLevel: Float = 0.3
    @Published var overlayVolumeBoost: Float = 0.2
    
    // MARK: - éŸ³é »æ ¸å¿ƒ
    private let speechSynthesizer = AVSpeechSynthesizer()
    private let audioSession = AVAudioSession.sharedInstance()
    
    // MARK: - ä¿®æ­£ï¼šéŸ³é »æœƒè©±ç®¡ç†ç‹€æ…‹ï¼ˆæ–°å¢åŸå§‹éŸ³é‡æ¢å¾©ï¼‰
    private var originalAudioCategory: AVAudioSession.Category?
    private var originalAudioOptions: AVAudioSession.CategoryOptions?
    private var originalSystemVolume: Float = 1.0  // æ–°å¢ï¼šè¨˜éŒ„åŸå§‹ç³»çµ±éŸ³é‡
    private var hasStoredOriginalSettings = false
    private var audioSessionConfigured = false
    private var shouldRestoreVolume = false  // æ–°å¢ï¼šæ¨™è¨˜æ˜¯å¦éœ€è¦æ¢å¾©éŸ³é‡
    
    // MARK: - éŸ³é »ç‹€æ…‹ç®¡ç†
    private var originalVolume: Float = 1.0
    private var wasOtherAudioPlaying = false
    private var audioMixState: AudioMixState = .normal
    private var currentAudioApp: String?
    private var isInterrupted = false
    
    // MARK: - éŸ³é »æ··åˆç‹€æ…‹
    private enum AudioMixState {
        case normal
        case smartDucking
        case videoOverlay
        case musicDucking
        case podcastPause
        case gameAudioMix
    }
    
    // MARK: - è¨­å®š
    private var _voiceLanguage: String = "zh-TW"
    private var _speechRate: Float = 0.5
    private var _speechVolume: Float = 1.0
    private var notificationDistance: Int = 2
    
    // MARK: - é˜²é‡è¤‡æ©Ÿåˆ¶
    private var lastAnnouncementTime: [String: Date] = [:]
    private let minimumAnnouncementInterval: TimeInterval = 5.0
    private var isSpeaking: Bool = false
    
    // MARK: - ç›®çš„åœ°è¿½è¹¤
    private var destinationRoute: String?
    private var destinationStop: String?
    private var hasNotifiedApproaching = false
    private var hasNotifiedArrival = false
    
    // MARK: - ä½ç½®è¿½è¹¤
    private var locationTrackingTimer: Timer?
    private var isTrackingActive = false
    
    override init() {
        super.init()
        setupHeadphoneDetection()
        setupSpeechDelegate()
        setupAudioInterruptionHandling()
        startAudioEnvironmentMonitoring()
        loadSettings()
        print("ğŸ”Š [Audio] AudioNotificationService åˆå§‹åŒ–å®Œæˆï¼ˆéä¾µå…¥å¼ï¼‰")
    }
    
    // MARK: - ä¿®æ­£ï¼šæŒ‰éœ€éŸ³é »æœƒè©±è¨­å®šï¼ˆåƒ…åœ¨æ’­å ±æ™‚è¨­å®šï¼‰
    
    private func prepareAudioSessionForSpeechOnly() {
        guard !audioSessionConfigured else {
            print("ğŸ”Š [Audio] éŸ³é »æœƒè©±å·²è¨­å®šï¼Œè·³éé‡è¤‡è¨­å®š")
            return
        }
        
        print("ğŸ”Š [Audio] === æº–å‚™èªéŸ³æ’­å ±éŸ³é »æœƒè©± ===")
        
        do {
            let audioSession = AVAudioSession.sharedInstance()
            
            // å„²å­˜åŸå§‹è¨­å®šï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡è¨­å®šæ™‚ï¼‰
            if !hasStoredOriginalSettings {
                originalAudioCategory = audioSession.category
                originalAudioOptions = audioSession.categoryOptions
                
                // æ–°å¢ï¼šè¨˜éŒ„åŸå§‹ç³»çµ±éŸ³é‡
                originalSystemVolume = AVAudioSession.sharedInstance().outputVolume
                
                hasStoredOriginalSettings = true
                print("ğŸ“¦ [Audio] å·²å„²å­˜åŸå§‹éŸ³é »è¨­å®š: \(originalAudioCategory?.rawValue ?? "æœªçŸ¥")")
                print("ğŸ”Š [Audio] å·²å„²å­˜åŸå§‹ç³»çµ±éŸ³é‡: \(originalSystemVolume)")
            }
            
            // æ›´æ™ºæ…§çš„éŸ³é »æ’­æ”¾ç‹€æ…‹æª¢æ¸¬
            let isOtherAudioPlaying = detectOtherAudioPlaying()
            wasOtherAudioPlaying = isOtherAudioPlaying
            
            print("ğŸµ [Audio] å…¶ä»–éŸ³é »æ’­æ”¾ç‹€æ…‹: \(isOtherAudioPlaying)")
            
            // ä¿®æ­£ï¼šç¸½æ˜¯ä½¿ç”¨æ··éŸ³æ¨¡å¼ï¼Œé¿å…ä¸­æ–·éŸ³æ¨‚
            if isOtherAudioPlaying && smartVolumeEnabled {
                // æœ‰å…¶ä»–éŸ³é »ä¸”é–‹å•Ÿæ™ºæ…§éŸ³é‡ï¼šä½¿ç”¨é™éŸ³æ··éŸ³
                try audioSession.setCategory(.playback, options: [.mixWithOthers, .duckOthers])
                print("ğŸµ [Audio] ä½¿ç”¨æ™ºæ…§é™éŸ³æ··éŸ³æ¨¡å¼")
                shouldRestoreVolume = true
            } else {
                // é è¨­ä½¿ç”¨éä¾µå…¥å¼æ··éŸ³ï¼ˆä¸æœƒä¸­æ–·ä»»ä½•éŸ³é »ï¼‰
                try audioSession.setCategory(.ambient, options: [.mixWithOthers])
                print("ğŸµ [Audio] ä½¿ç”¨éä¾µå…¥å¼æ··éŸ³æ¨¡å¼ï¼ˆé è¨­å®‰å…¨æ¨¡å¼ï¼‰")
                shouldRestoreVolume = false
            }
            
            try audioSession.setActive(true)
            audioSessionConfigured = true
            
            print("âœ… [Audio] èªéŸ³æ’­å ±éŸ³é »æœƒè©±è¨­å®šå®Œæˆ")
            
        } catch {
            print("âŒ [Audio] èªéŸ³æ’­å ±éŸ³é »æœƒè©±è¨­å®šå¤±æ•—: \(error.localizedDescription)")
            
            // å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æœ€å®‰å…¨çš„è¨­å®š
            do {
                try audioSession.setCategory(.ambient, options: [.mixWithOthers])
                try audioSession.setActive(true)
                audioSessionConfigured = true
                shouldRestoreVolume = false
                print("âœ… [Audio] ä½¿ç”¨å‚™ç”¨å®‰å…¨éŸ³é »è¨­å®š")
            } catch {
                print("âŒ [Audio] å‚™ç”¨éŸ³é »è¨­å®šä¹Ÿå¤±æ•—: \(error.localizedDescription)")
            }
        }
    }
    
    // æ–°å¢ï¼šæ›´æº–ç¢ºçš„éŸ³é »æ’­æ”¾ç‹€æ…‹æª¢æ¸¬
    private func detectOtherAudioPlaying() -> Bool {
        let audioSession = AVAudioSession.sharedInstance()
        
        // æ–¹æ³•1ï¼šæª¢æŸ¥ç³»çµ±ç‹€æ…‹
        let systemDetection = audioSession.isOtherAudioPlaying
        
        // æ–¹æ³•2ï¼šæª¢æŸ¥ Now Playing è³‡è¨Š
        let nowPlayingInfo = MPNowPlayingInfoCenter.default().nowPlayingInfo
        let hasNowPlayingInfo = nowPlayingInfo != nil && !nowPlayingInfo!.isEmpty
        
        // æ–¹æ³•3ï¼šæª¢æŸ¥éŸ³é »è¼¸å‡ºè·¯ç”±ï¼ˆæŸäº›æƒ…æ³ä¸‹å¯ä»¥æ¨æ¸¬ï¼‰
        let currentRoute = audioSession.currentRoute
        let hasAudioOutput = !currentRoute.outputs.isEmpty
        
        print("ğŸ” [Audio] éŸ³é »æª¢æ¸¬è©³æƒ…:")
        print("   ç³»çµ±æª¢æ¸¬: \(systemDetection)")
        print("   Now Playing è³‡è¨Š: \(hasNowPlayingInfo)")
        print("   éŸ³é »è¼¸å‡º: \(hasAudioOutput)")
        
        // æ›´ä¿å®ˆçš„åˆ¤æ–·ï¼šå¦‚æœæœ‰ä»»ä½•è·¡è±¡é¡¯ç¤ºå¯èƒ½æœ‰éŸ³é »ï¼Œå°±èªç‚ºæœ‰
        let finalResult = systemDetection || hasNowPlayingInfo
        
        print("   æœ€çµ‚åˆ¤æ–·: \(finalResult)")
        
        return finalResult
    }
    
    private func restoreOriginalAudioSession() {
        guard audioSessionConfigured else {
            print("ğŸ”Š [Audio] éŸ³é »æœƒè©±æœªè¨­å®šï¼Œç„¡éœ€æ¢å¾©")
            return
        }
        
        // å»¶é²æ¢å¾©ï¼Œé¿å…é »ç¹çš„éŸ³é »æœƒè©±åˆ‡æ›
        print("ğŸ”„ [Audio] === å»¶é²æ¢å¾©éŸ³é »è¨­å®šï¼ˆæ¸›å°‘éŸ³æ¨‚ä¸­æ–·ï¼‰===")
        
        DispatchQueue.main.asyncAfter(deadline: .now() + 2.0) { // å»¶é²2ç§’æ¢å¾©
            do {
                let audioSession = AVAudioSession.sharedInstance()
                
                // æº«å’Œçš„æ¢å¾©ï¼šä½¿ç”¨ notifyOthersOnDeactivation è®“å…¶ä»–éŸ³é »è‡ªç„¶æ¢å¾©
                try audioSession.setActive(false, options: [.notifyOthersOnDeactivation])
                
                // çŸ­æš«å»¶é²å¾Œæ¢å¾©åˆ°å®‰å…¨è¨­å®š
                DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                    do {
                        // æ°¸é ä½¿ç”¨å®‰å…¨çš„æ··éŸ³è¨­å®šï¼Œä¸æ¢å¾©åˆ°å¯èƒ½ä¸­æ–·éŸ³é »çš„åŸå§‹è¨­å®š
                        try audioSession.setCategory(.ambient, options: [.mixWithOthers])
                        try audioSession.setActive(true)
                        print("âœ… [Audio] æº«å’Œæ¢å¾©åˆ°å®‰å…¨æ··éŸ³è¨­å®š")
                    } catch {
                        print("â„¹ï¸ [Audio] ç³»çµ±éŸ³é »æœƒè©±ç”± iOS è‡ªå‹•ç®¡ç†")
                    }
                }
                
                self.audioSessionConfigured = false
                self.shouldRestoreVolume = false
                
                print("âœ… [Audio] éŸ³é »è¨­å®šæº«å’Œæ¢å¾©å®Œæˆ")
                
            } catch {
                print("â„¹ï¸ [Audio] éŸ³é »æœƒè©±ç”±ç³»çµ±è‡ªå‹•ç®¡ç†")
                self.audioSessionConfigured = false
                self.shouldRestoreVolume = false
            }
        }
    }
    
    // MARK: - æ™ºæ…§éŸ³é »ç’°å¢ƒåˆ†æ
    
    private func analyzeCurrentAudioEnvironment() -> AudioEnvironment {
        let audioSession = AVAudioSession.sharedInstance()
        let isOtherAudioPlaying = audioSession.isOtherAudioPlaying
        
        guard isOtherAudioPlaying else {
            return .silent
        }
        
        // åˆ†ææ­£åœ¨æ’­æ”¾çš„éŸ³é »é¡å‹
        let nowPlayingInfo = MPNowPlayingInfoCenter.default().nowPlayingInfo
        
        // æª¢æŸ¥æ‡‰ç”¨ç¨‹å¼é¡å‹
        if let artist = nowPlayingInfo?[MPMediaItemPropertyArtist] as? String {
            currentAudioApp = artist
            
            // å½±ç‰‡æ‡‰ç”¨ç¨‹å¼
            let videoApps = ["YouTube", "Netflix", "Disney+", "Prime Video", "HBO",
                             "Apple TV", "å½±ç‰‡", "Video", "TikTok", "Instagram"]
            if videoApps.contains(where: { artist.contains($0) }) {
                return .video
            }
            
            // æ’­å®¢/æœ‰è²æ›¸æ‡‰ç”¨ç¨‹å¼
            let podcastApps = ["Podcasts", "Apple Podcasts", "Overcast",
                               "æ’­å®¢", "æœ‰è²æ›¸", "Audible"]
            if podcastApps.contains(where: { artist.contains($0) }) {
                return .podcast
            }
        }
        
        // æª¢æŸ¥åª’é«”é¡å‹
        if let mediaType = nowPlayingInfo?[MPMediaItemPropertyMediaType] as? NSNumber {
            let type = MPMediaType(rawValue: mediaType.uintValue)
            if type.contains(.movie) || type.contains(.tvShow) || type.contains(.videoITunesU) {
                return .video
            }
            if type.contains(.podcast) || type.contains(.audioBook) {
                return .podcast
            }
        }
        
        // é è¨­ç‚ºéŸ³æ¨‚
        return .music
    }
    
    private enum AudioEnvironment {
        case silent
        case music
        case video
        case podcast
        case game
    }
    
    // MARK: - éŸ³é »ä¸­æ–·è™•ç†
    
    private func setupAudioInterruptionHandling() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleAudioInterruption),
            name: AVAudioSession.interruptionNotification,
            object: nil
        )
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(handleMediaServicesReset),
            name: AVAudioSession.mediaServicesWereResetNotification,
            object: nil
        )
    }
    
    @objc private func handleAudioInterruption(notification: Notification) {
        guard let info = notification.userInfo,
              let typeValue = info[AVAudioSessionInterruptionTypeKey] as? UInt,
              let type = AVAudioSession.InterruptionType(rawValue: typeValue) else {
            return
        }
        
        switch type {
        case .began:
            print("ğŸ”‡ [Audio] éŸ³é »ä¸­æ–·é–‹å§‹")
            isInterrupted = true
            if speechSynthesizer.isSpeaking {
                speechSynthesizer.pauseSpeaking(at: .immediate)
            }
            
        case .ended:
            print("ğŸ”Š [Audio] éŸ³é »ä¸­æ–·çµæŸ")
            
            // ä¿®æ­£ï¼šæ›´å¿«é€Ÿçš„ä¸­æ–·æ¢å¾©
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) {
                self.isInterrupted = false
                print("âœ… [Audio] ä¸­æ–·ç‹€æ…‹å·²é‡ç½®")
            }
            
            if let optionsValue = info[AVAudioSessionInterruptionOptionKey] as? UInt {
                let options = AVAudioSession.InterruptionOptions(rawValue: optionsValue)
                if options.contains(.shouldResume) {
                    // å»¶é²æ¢å¾©ï¼Œé¿å…ç«‹å³è¡çª
                    DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) {
                        if self.speechSynthesizer.isPaused {
                            self.speechSynthesizer.continueSpeaking()
                        }
                    }
                }
            }
            
        @unknown default:
            break
        }
    }
    
    @objc private func handleMediaServicesReset() {
        print("ğŸ”„ [Audio] åª’é«”æœå‹™é‡ç½®")
        audioSessionConfigured = false
        isInterrupted = false
        shouldRestoreVolume = false
    }
    
    // MARK: - çµ±ä¸€çš„èªéŸ³æ’­å ±æ–¹æ³•
    
    /// ç­‰è»Šæé†’ - æœ€é«˜å„ªå…ˆç´šï¼ˆä¿®æ­£ï¼šå¿½ç•¥ä¸­æ–·ç‹€æ…‹ï¼‰
    func announceWaitingBusAlert(_ message: String) {
        print("ğŸš¨ [Audio] ç­‰è»Šæé†’: \(message)")
        
        // æ’­æ”¾æ›´æœ‰è¶£çš„æç¤ºéŸ³
        AudioServicesPlaySystemSound(1016) // ä½¿ç”¨æ›´æ´»æ½‘çš„ç³»çµ±éŸ³æ•ˆ
        
        DispatchQueue.main.asyncAfter(deadline: .now() + 0.3) {
            let friendlyMessage = "\(message)"
            self.performSpeech(friendlyMessage, priority: .urgent, category: "waiting")
        }
    }
    
    /// åˆ°ç«™æé†’ - é«˜å„ªå…ˆç´š
    func announceArrivalAlert(_ message: String) {
        print("ğŸ¯ [Audio] åˆ°ç«™æé†’: \(message)")
        let friendlyMessage = "åˆ°ç«™äº†ï¼\(message)"
        performSpeech(friendlyMessage, priority: .high, category: "arrival")
    }
    
    /// æ¥è¿‘ç›®çš„åœ° - é«˜å„ªå…ˆç´š
    func announceApproachingDestination(_ message: String) {
        print("ğŸ”” [Audio] æ¥è¿‘æé†’: \(message)")
        let friendlyMessage = "å¿«åˆ°äº†ï¼\(message)"
        performSpeech(friendlyMessage, priority: .high, category: "approaching")
    }
    
    /// ä¸€èˆ¬ç«™é»è³‡è¨Š - æ™®é€šå„ªå…ˆç´š
    func announceStationInfo(stopName: String, arrivalTime: String? = nil) {
        let message = buildStationMessage(stopName: stopName, arrivalTime: arrivalTime)
        print("â„¹ï¸ [Audio] ç«™é»è³‡è¨Š: \(message)")
        performSpeech(message, priority: .normal, category: "station")
    }
    
    // MARK: - æ™ºæ…§éŸ³é »è¨­å®šæ–¹æ³•
    
    func toggleSmartVolume() {
        smartVolumeEnabled.toggle()
        saveSettings()
        
        let message = smartVolumeEnabled ? "æ™ºæ…§éŸ³é‡èª¿æ•´å·²é–‹å•Ÿ" : "æ™ºæ…§éŸ³é‡èª¿æ•´å·²é—œé–‰"
        performSpeech(message, priority: .normal, category: "settings")
    }
    
    func toggleVideoMode() {
        videoModeEnabled.toggle()
        saveSettings()
        
        let message = videoModeEnabled ? "å½±ç‰‡æ¨¡å¼å·²é–‹å•Ÿ" : "å½±ç‰‡æ¨¡å¼å·²é—œé–‰"
        performSpeech(message, priority: .normal, category: "settings")
    }
    
    func setDuckingLevel(_ level: Float) {
        duckingLevel = max(0.1, min(0.7, level))
        saveSettings()
        print("ğŸ”‰ [Audio] é™éŸ³ç¨‹åº¦è¨­å®šç‚º: \(duckingLevel)")
    }
    
    func setOverlayVolumeBoost(_ boost: Float) {
        overlayVolumeBoost = max(0.0, min(0.5, boost))
        saveSettings()
        print("ğŸ”Š [Audio] ç–ŠåŠ éŸ³é‡æå‡è¨­å®šç‚º: \(overlayVolumeBoost)")
    }
    
    // MARK: - æ ¸å¿ƒèªéŸ³æ’­å ±é‚è¼¯
    
    private func performSpeech(_ message: String, priority: SpeechPriority, category: String) {
        guard isAudioEnabled || priority == .urgent else {
            print("ğŸ”‡ [Audio] èªéŸ³å·²é—œé–‰ï¼Œè·³éæ’­å ±")
            return
        }
        
        // æª¢æŸ¥é‡è¤‡æ’­å ±
        if !canAnnounce(message, category: category, priority: priority) {
            return
        }
        
        // åªæœ‰ç·Šæ€¥æ’­å ±æ‰å¿½ç•¥ä¸­æ–·ç‹€æ…‹
        if isInterrupted && priority != .urgent {
            print("ğŸ”‡ [Audio] éŸ³é »è¢«ä¸­æ–·ï¼Œè·³ééç·Šæ€¥æ’­å ±")
            return
        }
        
        // åœæ­¢ç•¶å‰æ’­å ±ï¼ˆå¦‚æœæ˜¯æ›´é«˜å„ªå…ˆç´šï¼‰
        if priority.rawValue >= SpeechPriority.high.rawValue && speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        
        // åŸ·è¡Œæ’­å ±
        executeSpeech(message, priority: priority, category: category)
    }
    
    // æ–°å¢ï¼šå¼·åˆ¶åŸ·è¡ŒèªéŸ³æ’­å ±ï¼ˆå¿½ç•¥æ‰€æœ‰é™åˆ¶ï¼‰
    private func executeSpeechForced(_ message: String, priority: SpeechPriority, category: String) {
        print("ğŸš¨ [Audio] å¼·åˆ¶åŸ·è¡ŒèªéŸ³æ’­å ±: \(message)")
        
        // é‡ç½®ä¸­æ–·ç‹€æ…‹
        isInterrupted = false
        
        // åœæ­¢ç•¶å‰æ’­å ±
        if speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        
        // å¼·åˆ¶åŸ·è¡Œæ’­å ±
        executeSpeech(message, priority: priority, category: category)
    }
    
    // MARK: - èªéŸ³æ’­å ±æ–¹æ³•
    
    private func executeSpeech(_ message: String, priority: SpeechPriority, category: String) {
        // ä¿®æ­£ï¼šåœ¨æ’­å ±å‰æ‰è¨­å®šéŸ³é »æœƒè©±
        prepareAudioSessionForSpeechOnly()
        
        DispatchQueue.main.async {
            let utterance = AVSpeechUtterance(string: message)
            utterance.voice = AVSpeechSynthesisVoice(language: self._voiceLanguage)
            
            // æ ¹æ“šéŸ³é »ç‹€æ…‹å’Œå„ªå…ˆç´šå‹•æ…‹èª¿æ•´èªéŸ³åƒæ•¸
            self.configureUtteranceForCurrentState(utterance, priority: priority)
            
            // è¨˜éŒ„æ’­å ±æ­·å²
            self.updateAnnouncementHistory(message, category: category)
            
            // åŸ·è¡Œæ’­å ±
            self.speechSynthesizer.speak(utterance)
            self.isSpeaking = true
            print("ğŸ¤ [Audio] é–‹å§‹æ’­å ±: \(message)")
        }
    }
    
    private func configureUtteranceForCurrentState(_ utterance: AVSpeechUtterance, priority: SpeechPriority) {
        let baseRate = _speechRate
        let baseVolume = _speechVolume
        
        let currentEnvironment = analyzeCurrentAudioEnvironment()
        
        switch currentEnvironment {
        case .silent:
            // ç„¡å…¶ä»–éŸ³é »ï¼šæ­£å¸¸è¨­å®š
            utterance.rate = baseRate
            utterance.volume = baseVolume
            utterance.preUtteranceDelay = 0.2
            
        case .music:
            // éŸ³æ¨‚ç’°å¢ƒï¼šç¨å¾®æé«˜éŸ³é‡
            utterance.rate = baseRate
            utterance.volume = min(1.0, baseVolume + 0.1)
            utterance.preUtteranceDelay = 0.3
            
        case .video:
            // å½±ç‰‡ç’°å¢ƒï¼šæ˜é¡¯æé«˜éŸ³é‡å’Œæ¸…æ™°åº¦
            utterance.rate = max(0.4, baseRate - 0.1)
            utterance.volume = min(1.0, baseVolume + overlayVolumeBoost)
            utterance.preUtteranceDelay = 0.3
            
        case .podcast:
            // æ’­å®¢ç’°å¢ƒï¼šæ­£å¸¸è¨­å®šï¼ˆæœƒè¢«æš«åœï¼‰
            utterance.rate = baseRate
            utterance.volume = baseVolume
            utterance.preUtteranceDelay = 0.1
            
        case .game:
            // éŠæˆ²ç’°å¢ƒï¼šç¨å¾®æé«˜éŸ³é‡
            utterance.rate = baseRate
            utterance.volume = min(1.0, baseVolume + 0.1)
            utterance.preUtteranceDelay = 0.2
        }
        
        // å„ªå…ˆç´šèª¿æ•´
        if priority == .urgent {
            utterance.volume = min(1.0, utterance.volume + 0.2)
            utterance.rate = max(0.3, utterance.rate - 0.1)
        } else if priority == .high {
            utterance.volume = min(1.0, utterance.volume + 0.1)
        }
        
        print("ğŸ›ï¸ [Audio] èªéŸ³åƒæ•¸ - ç’°å¢ƒ:\(currentEnvironment), éŸ³é‡:\(utterance.volume), é€Ÿåº¦:\(utterance.rate)")
    }
    
    // MARK: - éŸ³é »æ¢å¾©æ©Ÿåˆ¶ï¼ˆå„ªåŒ–ç‰ˆï¼‰
    
    private func restoreAudioState() {
        print("ğŸ”„ [Audio] æ’­å ±å®Œæˆï¼Œæº–å‚™æ¢å¾©éŸ³é »ç‹€æ…‹")
        
        // å»¶é²æ¢å¾©ï¼Œç¢ºä¿æ’­å ±å®Œå…¨çµæŸ
        DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
            guard let self = self else { return }
            
            // æ¢å¾©åŸå§‹éŸ³é »è¨­å®š
            self.restoreOriginalAudioSession()
            
            // é‡ç½®ç‹€æ…‹
            self.audioMixState = .normal
            self.currentAudioApp = nil
            
            print("âœ… [Audio] éŸ³é »ç‹€æ…‹æ¢å¾©å®Œæˆ")
        }
    }
    
    // MARK: - AVSpeechSynthesizerDelegate å¯¦ç¾ï¼ˆæ–°å¢éŸ³é‡æ¢å¾©ï¼‰
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didFinish utterance: AVSpeechUtterance) {
        print("âœ… [Audio] èªéŸ³æ’­å ±å®Œæˆ")
        isSpeaking = false
        
        // æ’­å ±å®Œæˆå¾Œç«‹å³æ¢å¾©éŸ³é »ç‹€æ…‹
        restoreAudioState()
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didCancel utterance: AVSpeechUtterance) {
        print("âŒ [Audio] èªéŸ³æ’­å ±è¢«å–æ¶ˆ")
        isSpeaking = false
        
        // å–æ¶ˆæ™‚ä¹Ÿè¦æ¢å¾©éŸ³é »ç‹€æ…‹
        restoreAudioState()
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didStart utterance: AVSpeechUtterance) {
        print("ğŸ¤ [Audio] èªéŸ³æ’­å ±é–‹å§‹")
        isSpeaking = true
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didPause utterance: AVSpeechUtterance) {
        print("â¸ï¸ [Audio] èªéŸ³æ’­å ±æš«åœ")
    }
    
    func speechSynthesizer(_ synthesizer: AVSpeechSynthesizer, didContinue utterance: AVSpeechUtterance) {
        print("â–¶ï¸ [Audio] èªéŸ³æ’­å ±ç¹¼çºŒ")
    }
    
    // MARK: - é‡è¤‡æ’­å ±æª¢æŸ¥
    
    private func canAnnounce(_ content: String, category: String, priority: SpeechPriority) -> Bool {
        let key = "\(category)_\(content)"
        let now = Date()
        
        // ç·Šæ€¥å’Œæ¸¬è©¦æ’­å ±ç¸½æ˜¯å…è¨±
        if priority == .urgent {
            return true
        }
        
        // æª¢æŸ¥æ˜¯å¦æ­£åœ¨æ’­å ±
        if isSpeaking && priority.rawValue < SpeechPriority.high.rawValue {
            print("ğŸ”‡ [Audio] æ­£åœ¨æ’­å ±ä¸­ï¼Œè·³éä½å„ªå…ˆç´šå…§å®¹")
            return false
        }
        
        // æª¢æŸ¥é‡è¤‡é–“éš”
        if let lastTime = lastAnnouncementTime[key],
           now.timeIntervalSince(lastTime) < minimumAnnouncementInterval {
            print("ğŸ”‡ [Audio] é‡è¤‡å…§å®¹é–“éš”éçŸ­ï¼Œè·³éæ’­å ±")
            return false
        }
        
        return true
    }
    
    private func updateAnnouncementHistory(_ content: String, category: String) {
        let key = "\(category)_\(content)"
        lastAnnouncementTime[key] = Date()
    }
    
    // MARK: - ç›®çš„åœ°ç®¡ç†
    
    func setDestination(_ routeName: String, stopName: String) {
        print("ğŸ¯ [Audio] è¨­å®šç›®çš„åœ°: \(routeName) - \(stopName)")
        
        destinationRoute = routeName
        destinationStop = stopName
        targetStopName = stopName
        currentDestination = routeName.isEmpty ? stopName : "\(routeName) - \(stopName)"
        
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        startLocationTracking()
        
        let message = "ç›®çš„åœ°å·²è¨­å®šç‚º\(stopName)ï¼Œå°‡åœ¨æ¥è¿‘æ™‚æé†’æ‚¨"
        performSpeech(message, priority: .normal, category: "destination")
        
        updateNowPlayingInfo(with: "è¿½è¹¤ä¸­")
    }
    
    func clearDestination() {
        print("ğŸ—‘ï¸ [Audio] æ¸…é™¤ç›®çš„åœ°")
        
        let hadDestination = destinationRoute != nil || destinationStop != nil
        
        destinationRoute = nil
        destinationStop = nil
        targetStopName = nil
        currentDestination = nil
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        stopLocationTracking()
        
        if hadDestination {
            let message = "ç›®çš„åœ°å·²å–æ¶ˆ"
            performSpeech(message, priority: .normal, category: "destination")
        }
        
        updateNowPlayingInfo(with: "å¾…æ©Ÿä¸­")
    }
    
    // MARK: - ä½ç½®è¿½è¹¤
    
    private func startLocationTracking() {
        guard LocationService.shared.hasLocationPermission else {
            print("âš ï¸ [Audio] éœ€è¦ä½ç½®æ¬Šé™æ‰èƒ½é–‹å§‹è¿½è¹¤")
            return
        }
        
        stopLocationTracking()
        LocationService.shared.startUpdatingLocation()
        
        locationTrackingTimer = Timer.scheduledTimer(withTimeInterval: 15, repeats: true) { [weak self] _ in
            self?.checkLocationForDestination()
        }
        
        isTrackingActive = true
        print("ğŸ“ [Audio] å·²é–‹å§‹ä½ç½®è¿½è¹¤")
    }
    
    private func stopLocationTracking() {
        locationTrackingTimer?.invalidate()
        locationTrackingTimer = nil
        isTrackingActive = false
        LocationService.shared.stopUpdatingLocation()
        print("ğŸ›‘ [Audio] å·²åœæ­¢ä½ç½®è¿½è¹¤")
    }
    
    private func checkLocationForDestination() {
        guard let targetStop = destinationStop,
              let userLocation = LocationService.shared.currentLocation else {
            return
        }
        
        print("ğŸ“ [Audio] æª¢æŸ¥ä½ç½®ï¼šè·é›¢ç›®çš„åœ°è¨ˆç®—ä¸­...")
    }
    
    func checkDestinationProximity(currentStops: [BusStop.Stop], userLocation: CLLocation) {
        guard isTrackingActive,
              let targetStop = destinationStop else {
            return
        }
        
        guard let destinationStopData = currentStops.first(where: { $0.StopName.Zh_tw.contains(targetStop) }) else {
            return
        }
        
        let stopLocation = CLLocation(
            latitude: destinationStopData.StopPosition.PositionLat,
            longitude: destinationStopData.StopPosition.PositionLon
        )
        
        let distance = userLocation.distance(from: stopLocation)
        print("ğŸ“ [Audio] è·é›¢ç›®çš„åœ° \(Int(distance)) å…¬å°º")
        
        if distance <= 100 && !hasNotifiedArrival {
            announceArrivalAtDestination()
            hasNotifiedArrival = true
        } else if distance <= 300 && !hasNotifiedApproaching {
            announceApproachingDestination(distance: Int(distance))
            hasNotifiedApproaching = true
        }
    }
    
    private func announceApproachingDestination(distance: Int) {
        guard let targetStop = destinationStop else { return }
        let message = "æé†’æ‚¨ï¼Œå³å°‡åˆ°é”\(targetStop)ï¼Œè·é›¢ç´„\(distance)å…¬å°ºï¼Œè«‹æº–å‚™ä¸‹è»Š"
        announceApproachingDestination(message)
        updateNowPlayingInfo(with: "å³å°‡åˆ°ç«™")
    }
    
    private func announceArrivalAtDestination() {
        guard let targetStop = destinationStop else { return }
        let message = "\(targetStop)åˆ°äº†ï¼Œè«‹æº–å‚™ä¸‹è»Š"
        announceArrivalAlert(message)
        updateNowPlayingInfo(with: "å·²åˆ°é”")
    }
    
    // MARK: - éŸ³é »è¨­å®šæ–¹æ³•
    
    func toggleAudioNotifications() {
        isAudioEnabled.toggle()
        saveSettings()
        
        let message = isAudioEnabled ? "èªéŸ³æé†’é–‹å•Ÿ" : "èªéŸ³æé†’é—œé–‰"
        performSpeech(message, priority: .normal, category: "settings")
        updateNowPlayingInfo()
    }
    
    func setSpeechRate(_ rate: Float) {
        _speechRate = max(0.1, min(1.0, rate))
        saveSettings()
    }
    
    func setSpeechVolume(_ volume: Float) {
        _speechVolume = max(0.1, min(1.0, volume))
        saveSettings()
    }
    
    func setVoiceLanguage(_ language: String) {
        _voiceLanguage = language
        saveSettings()
    }
    
    // MARK: - è¼”åŠ©æ–¹æ³•
    
    private func buildStationMessage(stopName: String, arrivalTime: String?) -> String {
        var message = "å³å°‡åˆ°é”\(stopName)"
        
        if let time = arrivalTime, !time.isEmpty, time != message {
            message += "ï¼Œ\(time)"
        }
        
        return message
    }
    
    private func setupHeadphoneDetection() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(audioRouteChanged),
            name: AVAudioSession.routeChangeNotification,
            object: nil
        )
        checkHeadphoneConnection()
    }
    
    private func checkHeadphoneConnection() {
        let currentRoute = audioSession.currentRoute
        var headphonesConnected = false
        
        for output in currentRoute.outputs {
            switch output.portType {
            case .headphones, .bluetoothA2DP, .bluetoothHFP, .bluetoothLE:
                headphonesConnected = true
                break
            default:
                break
            }
        }
        
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            if self.isHeadphonesConnected != headphonesConnected {
                self.isHeadphonesConnected = headphonesConnected
                print("ğŸ§ [Audio] è€³æ©Ÿç‹€æ…‹è®Šæ›´: \(headphonesConnected ? "å·²é€£æ¥" : "å·²æ–·é–‹")")
            }
        }
    }
    
    private func setupSpeechDelegate() {
        speechSynthesizer.delegate = self
    }
    
    private func updateNowPlayingInfo(with status: String = "ç­‰è»Šä¸­") {
        var nowPlayingInfo = [String: Any]()
        
        if let destination = currentDestination {
            nowPlayingInfo[MPMediaItemPropertyTitle] = "å…¬è»Šä¾†äº†"
            nowPlayingInfo[MPMediaItemPropertyArtist] = destination
            nowPlayingInfo[MPMediaItemPropertyAlbumTitle] = status
        } else {
            nowPlayingInfo[MPMediaItemPropertyTitle] = "å…¬è»Šä¾†äº†"
            nowPlayingInfo[MPMediaItemPropertyArtist] = "æº–å‚™æ­è»Š"
            nowPlayingInfo[MPMediaItemPropertyAlbumTitle] = status
        }
        
        nowPlayingInfo[MPNowPlayingInfoPropertyIsLiveStream] = true
        nowPlayingInfo[MPNowPlayingInfoPropertyPlaybackRate] = isTrackingActive ? 1.0 : 0.0
        
        MPNowPlayingInfoCenter.default().nowPlayingInfo = nowPlayingInfo
    }
    
    // MARK: - æŒä¹…åŒ–
    
    private func saveSettings() {
        UserDefaults.standard.set(isAudioEnabled, forKey: "audioEnabled")
        UserDefaults.standard.set(smartVolumeEnabled, forKey: "smartVolumeEnabled")
        UserDefaults.standard.set(videoModeEnabled, forKey: "videoModeEnabled")
        UserDefaults.standard.set(duckingLevel, forKey: "duckingLevel")
        UserDefaults.standard.set(overlayVolumeBoost, forKey: "overlayVolumeBoost")
        UserDefaults.standard.set(notificationDistance, forKey: "notificationDistance")
        UserDefaults.standard.set(_speechRate, forKey: "speechRate")
        UserDefaults.standard.set(_speechVolume, forKey: "speechVolume")
        UserDefaults.standard.set(_voiceLanguage, forKey: "voiceLanguage")
    }
    
    private func loadSettings() {
        isAudioEnabled = UserDefaults.standard.bool(forKey: "audioEnabled")
        if !UserDefaults.standard.objectExists(forKey: "audioEnabled") {
            isAudioEnabled = true
        }
        
        smartVolumeEnabled = UserDefaults.standard.bool(forKey: "smartVolumeEnabled")
        if !UserDefaults.standard.objectExists(forKey: "smartVolumeEnabled") {
            smartVolumeEnabled = true
        }
        
        videoModeEnabled = UserDefaults.standard.bool(forKey: "videoModeEnabled")
        if !UserDefaults.standard.objectExists(forKey: "videoModeEnabled") {
            videoModeEnabled = true
        }
        
        duckingLevel = UserDefaults.standard.float(forKey: "duckingLevel")
        if duckingLevel == 0 { duckingLevel = 0.3 }
        
        overlayVolumeBoost = UserDefaults.standard.float(forKey: "overlayVolumeBoost")
        if overlayVolumeBoost == 0 { overlayVolumeBoost = 0.2 }
        
        notificationDistance = UserDefaults.standard.integer(forKey: "notificationDistance")
        _speechRate = UserDefaults.standard.float(forKey: "speechRate")
        _speechVolume = UserDefaults.standard.float(forKey: "speechVolume")
        _voiceLanguage = UserDefaults.standard.string(forKey: "voiceLanguage") ?? "zh-TW"
        
        if notificationDistance == 0 { notificationDistance = 2 }
        if _speechRate == 0 { _speechRate = 0.5 }
        if _speechVolume == 0 { _speechVolume = 1.0 }
    }
    
    func resetNotificationStatus() {
        lastAnnouncementTime.removeAll()
        hasNotifiedApproaching = false
        hasNotifiedArrival = false
        
        if speechSynthesizer.isSpeaking {
            speechSynthesizer.stopSpeaking(at: .immediate)
        }
        isSpeaking = false
        
        // é‡ç½®æ™‚ä¹Ÿæ¢å¾©éŸ³é »ç‹€æ…‹
        if audioSessionConfigured {
            restoreOriginalAudioSession()
        }
        
        print("ğŸ”„ [Audio] å·²é‡ç½®éŸ³é »é€šçŸ¥ç‹€æ…‹")
    }
    
    // MARK: - éŸ³é »ç’°å¢ƒç›£æ§ï¼ˆåƒ…ç›£æ§è®ŠåŒ–ï¼‰
    
    func startAudioEnvironmentMonitoring() {
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(nowPlayingInfoChanged),
            name: .MPMusicPlayerControllerNowPlayingItemDidChange,
            object: nil
        )
        
        NotificationCenter.default.addObserver(
            self,
            selector: #selector(playbackStateChanged),
            name: .MPMusicPlayerControllerPlaybackStateDidChange,
            object: nil
        )
        
        print("ğŸµ [Audio] éŸ³é »ç’°å¢ƒç›£æ§å·²å•Ÿå‹•ï¼ˆåƒ…ç›£æ§è®ŠåŒ–ï¼‰")
    }
    
    // MARK: - èª¿è©¦å’Œè¨ºæ–·æ–¹æ³•
    
    func getCurrentAudioEnvironmentInfo() -> String {
        let environment = analyzeCurrentAudioEnvironment()
        let audioSession = AVAudioSession.sharedInstance()
        
        var info = "éŸ³é »ç’°å¢ƒ: \(environment)\n"
        info += "æ··åˆç‹€æ…‹: \(audioMixState)\n"
        info += "å…¶ä»–éŸ³é »æ’­æ”¾: \(audioSession.isOtherAudioPlaying)\n"
        info += "è€³æ©Ÿé€£æ¥: \(isHeadphonesConnected)\n"
        info += "æ™ºæ…§éŸ³é‡: \(smartVolumeEnabled)\n"
        info += "å½±ç‰‡æ¨¡å¼: \(videoModeEnabled)\n"
        info += "éŸ³é »æœƒè©±å·²è¨­å®š: \(audioSessionConfigured)\n"
        info += "éœ€è¦æ¢å¾©éŸ³é‡: \(shouldRestoreVolume)\n"
        
        if let app = currentAudioApp {
            info += "éŸ³é »App: \(app)\n"
        }
        
        let nowPlayingInfo = MPNowPlayingInfoCenter.default().nowPlayingInfo
        if let title = nowPlayingInfo?[MPMediaItemPropertyTitle] as? String {
            info += "æ­£åœ¨æ’­æ”¾: \(title)\n"
        }
        
        return info
    }
    
    func forceAudioEnvironmentRefresh() {
        print("ğŸ”„ [Audio] å¼·åˆ¶åˆ·æ–°éŸ³é »ç’°å¢ƒï¼ˆåƒ…æ›´æ–°ç‹€æ…‹ï¼‰")
    }
    
    // MARK: - éŸ³é »ç’°å¢ƒç›£æ§è™•ç†ï¼ˆåƒ…è¨˜éŒ„è®ŠåŒ–ï¼‰
    
    @objc private func audioRouteChanged(notification: Notification) {
        checkHeadphoneConnection()
        print("ğŸ§ [Audio] éŸ³é »è·¯å¾‘è®Šæ›´")
    }
    
    @objc private func nowPlayingInfoChanged() {
        print("ğŸµ [Audio] æ­£åœ¨æ’­æ”¾è³‡è¨Šè®Šæ›´")
    }
    
    @objc private func playbackStateChanged() {
        print("â¯ï¸ [Audio] æ’­æ”¾ç‹€æ…‹è®Šæ›´")
    }
    
    // MARK: - å±¬æ€§è¨ªå•å™¨
    
    var voiceLanguage: String { _voiceLanguage }
    var speechRate: Float { _speechRate }
    var speechVolume: Float { _speechVolume }
    
    // MARK: - æ¸…ç†æ–¹æ³•
    
    deinit {
        stopLocationTracking()
        NotificationCenter.default.removeObserver(self)
        speechSynthesizer.stopSpeaking(at: .immediate)
        
        // ç¢ºä¿æ¢å¾©éŸ³é »è¨­å®š
        if audioSessionConfigured {
            restoreOriginalAudioSession()
        }
        
        print("ğŸ—‘ï¸ [Audio] AudioNotificationService å·²æ¸…ç†")
    }
}

// MARK: - èªéŸ³å„ªå…ˆç´š
private enum SpeechPriority: Int, CaseIterable {
    case normal = 1
    case high = 2
    case urgent = 3
}

// MARK: - UserDefaults æ“´å±•
extension UserDefaults {
    func objectExists(forKey key: String) -> Bool {
        return object(forKey: key) != nil
    }
}
